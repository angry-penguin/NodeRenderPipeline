#include "Packages/com.arycama.noderenderpipeline/ShaderLibrary/Deferred.hlsl"
#include "Packages/com.arycama.noderenderpipeline/ShaderLibrary/Geometry.hlsl"
#include "Packages/com.arycama.noderenderpipeline/ShaderLibrary/Lighting.hlsl"
#include "Packages/com.arycama.noderenderpipeline/ShaderLibrary/SpaceTransforms.hlsl"

#pragma kernel Compute
#pragma kernel Temporal
#pragma kernel Spatial
#pragma kernel Combine

RWTexture2D<float4> _VisibilityCone;
RWTexture2D<float> _FrameCountResult;
RWTexture2D<uint> _Result;
Texture2D<float3> _PreviousFrame;
Texture2D<float2> _Motion;
Texture2D<float> _Depth, _PreviousDepth, _FrameCountPrevious, _FrameCount;
Texture2D<uint> _Input, _History;

cbuffer AOConstants
{
	float4 _UvToView;
	float _SampleCount, _Strength, _ThinOccluderCompensation, _MaxScreenRadius, _FalloffScale, _FalloffBias, _Radius, _SampleDistributionPower, _DepthMipSamplingOffset, _MaxMips, _ClampWindowScale, _DepthRejection, _VelocityRejection, _ClampVelocityWeight, _AccumFrameCount, _DirectionCount, _WorldRadius;
	float _DistanceWeight, _NormalWeight, _TangentWeight, _BlurRadius;
	int _BlurSamples, _Width, _Height;
	uint _MaxWidth, _MaxHeight;
};

// Inputs are screen XY and viewspace depth, output is viewspace position
float3 ComputeViewspacePosition(float2 screenPos, float viewspaceDepth)
{
	float3 ret;
	ret.xy = (screenPos * _ScreenSize.zw * _UvToView.xy + _UvToView.zw) * viewspaceDepth;
	ret.z = viewspaceDepth;
	return ret;
}

uint PackOutput(float4 input)
{
	input /= 1.5;
	input.xyz = 0.5 * input.xyz + 0.5;
	uint4 result = uint4(saturate(input) * 255.0 + 0.5);
	return result.x | (result.y << 8) | (result.z << 16) | (result.w << 24);
}

float4 UnpackInput(uint input)
{
	float4 output = (input >> uint4(0, 8, 16, 24)) & 0xFF;
	output = output / 255.0;
	output.xyz = 2.0 * output.xyz - 1.0;
	return output * 1.5;
}

[numthreads(8, 8, 1)]
void Compute(uint2 id : SV_DispatchThreadID)
{
	// Half res
	float2 rcpScaleFactor = rcp(0.5);
	float2 pixelCenter = floor((id + 0.5) * rcpScaleFactor + _Jitter * _ScreenSize.xy) + 0.5;
	
	float3 N = GBufferNormal(pixelCenter);
	float3 normalV = WorldToViewDir(N, true);
	float2 noise = _BlueNoise2D[id % 128];

	float viewspaceZ = LinearEyeDepth(_Depth[pixelCenter]);
	float3 cPosV = ComputeViewspacePosition(pixelCenter, viewspaceZ);
	float3 viewV = normalize(-cPosV);

	float screenspaceRadius = min(_MaxScreenRadius, _Radius / viewspaceZ);
	float ratio = saturate(_MaxScreenRadius / (_Radius / viewspaceZ));
	
	float4 result = 0.0;
	for (float i = 0; i < _DirectionCount; i++)
	{
		float phi = Pi / _DirectionCount * (i + noise.x);
		float3 directionV = float3(cos(phi), sin(phi), 0.0);
		
		float3 orthoDirectionV = ProjectOnPlane(directionV, viewV);
		float3 axisV = normalize(cross(directionV, viewV));
		float3 projNormalV = ProjectOnPlane(normalV, axisV);
	
		float sgnN = sign(dot(orthoDirectionV, projNormalV));
		float cosN = saturate(dot(projNormalV, viewV) / length(projNormalV));
		float n = sgnN * FastACos(cosN);
		
		float2 h;
		
		[unroll]
		for (uint side = 0; side < 2; side++)
		{
			// Find the intersection with the next pixel, and use that as the starting point for the ray
			float2 direction = directionV.xy * (2.0 * side - 1.0);
			float2 cell = floor(pixelCenter);
			float2 tMin = (cell - pixelCenter) / direction;
			float2 tMax = (cell - pixelCenter + 1.0) / direction;
			float t = Max2(max(tMin, tMax));
			float2 start = pixelCenter + direction * t;
			float2 end = pixelCenter + direction * screenspaceRadius;
			float2 step = (end - start) / _SampleCount;
			
			float lowHorizonCos = cos(n + (2.0 * side - 1.0) * HalfPi);
			float cHorizonCos = lowHorizonCos;
			
			for (float j = 0.0; j < _SampleCount; j++)
			{
				float2 position = start + (j + noise.y) * step;
				float SZ = LinearEyeDepth(_Depth[position]);
				float3 sPosV = ComputeViewspacePosition(position, SZ);
				float3 sHorizonV = normalize(sPosV - cPosV);

				// Falloff
				float start = _WorldRadius * 0.75 * ratio;
				float end = _WorldRadius * ratio;
				float weight = saturate((end - distance(sPosV, cPosV)) / (end - start));
				float sHorizonCos = lerp(lowHorizonCos, dot(sHorizonV, viewV), weight);
			
				if (sHorizonCos >= cHorizonCos)
				{
					// If weighted horizon is greater than the previous sample, it becomes the new horizon
					cHorizonCos = sHorizonCos;
				}
				else if (dot(sHorizonV, viewV) < cHorizonCos)
				{
					// Otherwise, reduce the max horizon to attenuate thin features, but only if the -non- weighted sample is also below the current sample
					// This prevents the falloff causing objects to be treated as thin when they would not be otherwise
					cHorizonCos = max(lowHorizonCos, cHorizonCos - _ThinOccluderCompensation);
				}
			}

			h[side] = n + clamp((2.0 * side - 1.0) * FastACos(cHorizonCos) - n, -HalfPi, HalfPi);
			result.w += length(projNormalV) * (cosN + 2.0 * h[side] * sin(n) - cos(2.0 * h[side] - n)) / 4.0;
		}
		
		// see "Algorithm 2 Extension that computes bent normals b."
		float t0 = (6 * sin(h[0] - n) - sin(3 * h[0] - n) + 6 * sin(h[1] - n) - sin(3 * h[1] - n) + 16 * sin(n) - 3 * (sin(h[0] + n) + sin(h[1] + n))) / 12;
		float t1 = (-cos(3 * h[0] - n) - cos(3 * h[1] - n) + 8 * cos(n) - 3 * (cos(h[0] + n) + cos(h[1] + n))) / 12;
	
		float3 bentNormalL = normalize(float3(directionV.x * t0, directionV.y * t0, -t1));
		result.xyz += mul(RotFromToMatrix(float3(0, 0, -1), viewV), bentNormalL) * length(projNormalV);
	}
	
	result /= _DirectionCount;
		
	result.xyz = ViewToWorldDir(result.xyz, false);
	_Result[id] = PackOutput(result);
}

[numthreads(8, 8, 1)]
void Temporal(uint2 id : SV_DispatchThreadID)
{
	float2 uv = (id + 0.5) / _ScreenSize.xy;
	uint4 input = _Input.Gather(_PointClampSampler, uv).xywz;
	
	float4 result = 0.0, minValue = FloatMax, maxValue = FloatMin;
	float maxWeight = 0.0, weightSum = 0.0;
	
	// Half res
	float2 rcpScaleFactor = rcp(0.5);
	float2 jitteredPixelCenter = uv + _Jitter * _ScreenSize.xy;
	
	[unroll]
	for (uint y = 0, i = 0; y < 2; y++)
	{
		[unroll]
		for (uint x = 0; x < 2; x++, i++)
		{
			float4 color = UnpackInput(input[i]);
			float2 fullResCoord = (((id - 1) >> 1) + int2(x, y)) * 2 + 1 + _Jitter * _ScreenSize.xy;
			float2 delta = abs(fullResCoord - id + 0.5);
			float weight = saturate(1.0 - delta.x) * saturate(1.0 - delta.y);
			
			maxWeight = max(maxWeight, weight);
			weightSum += weight;
			result += color * weight;
			minValue = min(minValue, color);
			maxValue = max(maxValue, color);
		}
	}
	
	if(weightSum > 0.0)
		result /= weightSum;
	
	// Sample history, remove weighting from history and result, blend, re-apply weight
	float2 previousUv = uv - _Motion[id];
	uint4 packedHistory = _History.Gather(_PointClampSampler, previousUv);
	float4 bilinearWeights = BilinearWeights(previousUv, _ScreenSize.xy);
	float4 history = 0.0;
	
	[unroll]
	for (i = 0; i < 4; i++)
	{
		float4 historySample = UnpackInput(packedHistory[i]);
		history += bilinearWeights[i] * historySample;
	}
	
	//history = clamp(history, minValue, maxValue);
	
	result = lerp(history, result, maxWeight);
	
	_Result[id] = PackOutput(result);
}

[numthreads(8, 8, 1)]
void Spatial(uint2 id : SV_DispatchThreadID)
{
	float frameCount = _FrameCount[id];
	float phi = _BlueNoise1D[id % 128] * TwoPi;
	float centerDepth = LinearEyeDepth(_Depth[id]);
 
	float4 result = 0.0;
	float weightSum = 0.0;
	
	float sigma = lerp(1.0 / (_BlurRadius / 2.0 + 1.0), 0.5, frameCount);
	
	int radius = _BlurSamples / 2;
	for (int y = -radius; y <= radius; y++)
	{
		for (int x = -radius; x <= radius; x++)
		{
			int2 coord = id + int2(x, y);
			
			if(any(coord < 0 || coord >= _ScreenSize.xy))
				continue;
			
			float sampleDepth = LinearEyeDepth(_Depth[coord]);
			float weight = saturate(1.0 - abs(sampleDepth - centerDepth) * _DistanceWeight / centerDepth);
			weight *= saturate(1.0 - abs(x * sigma)) * saturate(1.0 - abs(y * sigma));
			
			result += UnpackInput(_Input[coord]) * weight;
			weightSum += weight;
		}
	}
	
	result /= weightSum;
	
	_Result[id] = PackOutput(result);
	_Result[id] = _Input[id];
}

[numthreads(8, 8, 1)]
void Combine(uint2 id : SV_DispatchThreadID)
{
	float2 uv = (id + 0.5) / _ScreenSize.xy;//	+_Jitter;
	uint4 inputs = _Input.Gather(_PointClampSampler, uv);
	float4 weights = BilinearWeights(uv, _ScreenSize.xy);
	
	float4 result = 0.0;
	
	[unroll]
	for (uint i = 0; i < 4; i++)
		result += UnpackInput(inputs[i]) * weights[i];
	
	// Remove weighting from final result
	result /= length(result.rgb);
	
	// Apply final modifier after temporal to reduce variance
	result.a = pow(result.a, _Strength);
	
	float4 visibilityCone = _VisibilityCone[id];
	visibilityCone.xyz = GBufferNormal(visibilityCone);
	visibilityCone = BlendVisibiltyCones(visibilityCone, result);
	//visibilityCone = result;
	
	_VisibilityCone[id] = PackGBufferNormal(visibilityCone.xyz, visibilityCone.w);
}
#include "Packages/com.arycama.noderenderpipeline/ShaderLibrary/Lighting.hlsl"
#include "Packages/com.arycama.noderenderpipeline/ShaderLibrary/Deferred.hlsl"
#include "Packages/com.arycama.noderenderpipeline/ShaderLibrary/Geometry.hlsl"
#include "Packages/com.unity.render-pipelines.core/ShaderLibrary/ImageBasedLighting.hlsl"

#pragma kernel Compute
#pragma kernel Temporal
#pragma kernel Spatial
#pragma kernel Combine

RWTexture2D<float4> _VisibilityCone;
RWTexture2D<float> _FrameCountResult;
RWTexture2D<uint> _Result;
Texture2D<float3> _PreviousFrame;
Texture2D<float> _Depth, _PreviousDepth, _FrameCountPrevious, _FrameCount;
Texture2D<uint> _Motion, _Input, _History;

cbuffer AOConstants
{
	float4 _UvToView;
	float _SampleCount, _Strength, _ThinOccluderCompensation, _MaxScreenRadius, _FalloffScale, _FalloffBias, _Radius, _SampleDistributionPower, _DepthMipSamplingOffset, _MaxMips, _ClampWindowScale, _DepthRejection, _VelocityRejection, _ClampVelocityWeight, _AccumFrameCount, _DirectionCount, _WorldRadius;
	float _DistanceWeight, _NormalWeight, _TangentWeight;
	uint _BlurSamples;
	uint _MaxWidth, _MaxHeight;
};

// Inputs are screen XY and viewspace depth, output is viewspace position
float3 ComputeViewspacePosition(float2 screenPos, float viewspaceDepth)
{
	float3 ret;
	ret.xy = (screenPos * _ScreenSize.zw * _UvToView.xy + _UvToView.zw) * viewspaceDepth;
	ret.z = viewspaceDepth;
	return ret;
}

uint PackOutput(float4 input)
{
	input /= 1.5;
	input.xyz = 0.5 * input.xyz + 0.5;
	uint4 result = uint4(saturate(input) * 255.0 + 0.5);
	return result.x | (result.y << 8) | (result.z << 16) | (result.w << 24);
}

float4 UnpackInput(uint input)
{
	float4 output = (input >> uint4(0, 8, 16, 24)) & 0xFF;
	output = output / 255.0;
	output.xyz = 2.0 * output.xyz - 1.0;
	return output * 1.5;
}

[numthreads(8, 8, 1)]
void Compute(uint2 id : SV_DispatchThreadID)
{
	float2 pixelCenter = floor(id * 2 + 1 + _Jitter * _ScreenSize.xy) + 0.5;
	
	float3 N = GBufferNormal(pixelCenter);
	float3 normalV = WorldToViewDir(N, true);
	float2 noise = _BlueNoise2D[id % 128];

	float viewspaceZ = LinearEyeDepth(_Depth[pixelCenter], _ZBufferParams);
	float3 cPosV = ComputeViewspacePosition(pixelCenter, viewspaceZ);
	float3 viewV = normalize(-cPosV);

	float screenspaceRadius = min(_MaxScreenRadius, _Radius / viewspaceZ);
	float ratio = saturate(_MaxScreenRadius / (_Radius / viewspaceZ));
	
	float4 result = 0.0;
	for (float i = 0; i < _DirectionCount; i++)
	{
		float phi = PI / _DirectionCount * (i + noise.x);
		float3 directionV = float3(cos(phi), sin(phi), 0.0);
		
		float3 orthoDirectionV = ProjectOnPlane(directionV, viewV);
		float3 axisV = normalize(cross(directionV, viewV));
		float3 projNormalV = ProjectOnPlane(normalV, axisV);
	
		float sgnN = sign(dot(orthoDirectionV, projNormalV));
		float cosN = saturate(dot(projNormalV, viewV) / length(projNormalV));
		float n = sgnN * FastACos(cosN);
		
		float2 h;
		
		[unroll]
		for (uint side = 0; side < 2; side++)
		{
						// Find the intersection with the next pixel, and use that as the starting point for the ray
			float2 direction = directionV.xy * (2.0 * side - 1.0);
			float2 cell = floor(pixelCenter);
			float2 tMin = (cell - pixelCenter) / direction;
			float2 tMax = (cell - pixelCenter + 1.0) / direction;
			float t = Max2(max(tMin, tMax));
			float2 start = pixelCenter + direction * t;
			float2 end = pixelCenter + direction * screenspaceRadius;
			float2 step = (end - start) / _SampleCount;
			
			float lowHorizonCos = cos(n + (2.0 * side - 1.0) * HALF_PI);
			float cHorizonCos = lowHorizonCos;
			
			for (float j = 0.0; j < _SampleCount; j++)
			{
				float2 position = start + (j + noise.y) * step;
				float SZ = LinearEyeDepth(_Depth[position], _ZBufferParams);
				float3 sPosV = ComputeViewspacePosition(position, SZ);
				float3 sHorizonV = normalize(sPosV - cPosV);

				// Falloff
				float start = _WorldRadius * 0.75 * ratio;
				float end = _WorldRadius * ratio;
				float weight = saturate((end - distance(sPosV, cPosV)) / (end - start));
				float sHorizonCos = lerp(lowHorizonCos, dot(sHorizonV, viewV), weight);
			
				if (sHorizonCos >= cHorizonCos)
				{
					// If weighted horizon is greater than the previous sample, it becomes the new horizon
					cHorizonCos = sHorizonCos;
				}
				else if (dot(sHorizonV, viewV) < cHorizonCos)
				{
					// Otherwise, reduce the max horizon to attenuate thin features, but only if the -non- weighted sample is also below the current sample
					// This prevents the falloff causing objects to be treated as thin when they would not be otherwise
					cHorizonCos = max(lowHorizonCos, cHorizonCos - _ThinOccluderCompensation);
				}
			}

			h[side] = n + clamp((2.0 * side - 1.0) * FastACos(cHorizonCos) - n, -HALF_PI, HALF_PI);
			result.w += length(projNormalV) * (cosN + 2.0 * h[side] * sin(n) - cos(2.0 * h[side] - n)) / 4.0;
		}
		
		// see "Algorithm 2 Extension that computes bent normals b."
		float t0 = (6 * sin(h[0] - n) - sin(3 * h[0] - n) + 6 * sin(h[1] - n) - sin(3 * h[1] - n) + 16 * sin(n) - 3 * (sin(h[0] + n) + sin(h[1] + n))) / 12;
		float t1 = (-cos(3 * h[0] - n) - cos(3 * h[1] - n) + 8 * cos(n) - 3 * (cos(h[0] + n) + cos(h[1] + n))) / 12;
	
		float3 bentNormalL = normalize(float3(directionV.x * t0, directionV.y * t0, -t1));
		result.xyz += mul(RotFromToMatrix(float3(0, 0, -1), viewV), bentNormalL) * length(projNormalV);
	}
	
	result /= _DirectionCount;
		
	result.xyz = ViewToWorldDir(result.xyz, false);
	_Result[id] = PackOutput(result);
}

[numthreads(8, 8, 1)]
void Temporal(uint2 dispatchThreadId : SV_DispatchThreadID, uint2 groupThreadId : SV_GroupThreadID, uint2 groupId : SV_GroupID)
{
	float2 pixCenter = dispatchThreadId + 0.5;
	float2 uv = pixCenter * _ScreenSize.zw;
	uint4 input = _Input.Gather(_PointClampSampler, uv).xywz;
	
	float maxWeight = 0.0, weightSum = 0.0;
	float4 current = 0.0, mean = 0.0, stdDev = 0.0;
	
	[unroll]
	for (uint y = 0, i = 0; y < 2; y++)
	{
		[unroll]
		for (uint x = 0; x < 2; x++, i++)
		{
			int2 lowResCoord = clamp(((dispatchThreadId - 1) >> 1) + int2(x, y), 0, floor(_ScreenSize.xy * 0.5) - 1);
			float4 color = UnpackInput(_Input[lowResCoord]);
			
			float2 fullResCoord = lowResCoord * 2 + 1 + _Jitter * _ScreenSize.xy;
			float2 delta = abs(fullResCoord - dispatchThreadId + 0.5);
			float weight = saturate(1.0 - delta.x) * saturate(1.0 - delta.y);
			
			maxWeight = max(maxWeight, weight);
			weightSum += weight;
			current += color * weight;
			mean += color;
			stdDev += color * color;
		}
	}
	
	if(weightSum > 0.0)
		current /= weightSum;
	
	mean /= 4.0;
	stdDev = sqrt(abs(stdDev / 4.0 - mean * mean));
	
	float3 velocity = UnpackVelocity(_Motion[dispatchThreadId]);
	float2 previousUv = (dispatchThreadId + 0.5) * _ScreenSize.zw - velocity.xy;
		
	// Sample history, remove weighting from history and current, blend, re-apply weight
	uint4 packedHistory = _History.Gather(_PointClampSampler, previousUv).xywz;
	float4 previousDepths = _PreviousDepth.Gather(_PointClampSampler, previousUv).xywz;
	float4 frameCounts = _FrameCountPrevious.Gather(_PointClampSampler, previousUv).xywz * 255.0;
	float4 bilinearWeights = BilinearWeights(previousUv, _ScreenSize.xy).xywz;
		
	float2 previousCoord = floor(previousUv * _ScreenSize.xy - 0.5);
	float2 previousFrac = frac(previousUv * _ScreenSize.xy - 0.5);
	
	float4 history = 0.0;
	float historyWeightSum = 0.0, accumWeightSum = 0.0, accumSpeed = 0.0;
	float currentDepth = Linear01ToDeviceDepth(Linear01Depth(_Depth[dispatchThreadId], _ZBufferParams) - velocity.z, _ZBufferParams);
	
	// Compute disocclusion basing on plane distance
	float3 Xprev = MultiplyPointProj(_PrevInvViewProjMatrix, float3(previousUv * 2.0 - 1.0, currentDepth)).xyz;
	float3 Xvprev = MultiplyPoint(_PrevViewMatrix, Xprev);
	//float NoXprev = dot(N, Xprev);
	//float NoVprev = NoXprev / Xvprev.z;
	//float4 planeDist = abs(NoVprev * viewZprev - NoXprev);
	float invDistToPoint = rcp(LinearEyeDepth(_Depth[dispatchThreadId], _ZBufferParams));
	//float4 occlusion = step(gDisocclusionThreshold, planeDist * invDistToPoint);
	//occlusion = saturate(float(isInScreen) - occlusion);
	
	[unroll]
	for (y = 0, i = 0; y < 2; y++)
	{
		[unroll]
		for (int x = 0; x < 2; x++, i++)
		{
			float2 coord = previousCoord + float2(x, y);
			
			if (any(coord < 0 || coord >= _ScreenSize.xy))
				continue;
			
			float3 previousPositionWS = MultiplyPointProj(_PrevInvViewProjMatrix, float3(((coord + 0.5) / _ScreenSize.xy) * 2 - 1, previousDepths[i])).xyz;
			float weight = saturate(1.0 - distance(Xprev, previousPositionWS) * _DepthRejection * invDistToPoint);
			weight *= saturate(1.0 - length(velocity) * _VelocityRejection);
			weight *= bilinearWeights[i];
			
			float4 historySample = UnpackInput(packedHistory[i]);
			history += historySample * weight;
			historyWeightSum += weight;
			accumSpeed += frameCounts[i] * weight;
			accumWeightSum += bilinearWeights[i];
		}
	}
	
	if (historyWeightSum > 0.0)
		history /= historyWeightSum;
	
	if (accumWeightSum > 0.0)
		accumSpeed /= accumWeightSum;
	
	accumSpeed = min(accumSpeed, _AccumFrameCount);
	float speed = 1.0 / (1.0 + accumSpeed);
	
	float velocityWeight = saturate(1.0 - length(velocity) * _ClampVelocityWeight);
	float4 extents = stdDev * (1.0 + _ClampWindowScale * velocityWeight);
	history = clamp(history, mean - extents, mean + extents);
	
	float t = speed * maxWeight;
	current = lerp(history, current, t);
	
	_Result[dispatchThreadId] = PackOutput(current);
	_FrameCountResult[dispatchThreadId] = (accumSpeed + 1.0) / 255.0;
	//_Result[dispatchThreadId] = _Input[dispatchThreadId >> 1];
}

[numthreads(8, 8, 1)]
void Spatial(uint2 dispatchThreadId : SV_DispatchThreadID, uint2 groupThreadId : SV_GroupThreadID, uint2 groupId : SV_GroupID)
{
	float frameCount = _FrameCount[dispatchThreadId] * 255.0;
	float phi = _BlueNoise1D[dispatchThreadId % 128] * TWO_PI;
	float depth = _Depth[dispatchThreadId];
	float3 positionWS = PixelToWorld(dispatchThreadId + 0.5, depth);
 
	float4 result = UnpackInput(_Input[dispatchThreadId]);
	float weightSum = 1.0;
	
	float3 normal = GBufferNormal(dispatchThreadId);
	float3x3 frame = GetLocalFrame(normal);
	
	float rcpEyeDepth = rcp(LinearEyeDepth(depth, _ZBufferParams));
	float ratio = saturate(_MaxScreenRadius / (_Radius * rcpEyeDepth));
	float radius = _WorldRadius * ratio * (1.0 / (1.0 + frameCount));
	
	// Tangent plane
	float4 plane = float4(normal, -dot(normal, positionWS));
	
	for (uint i = 0; i < _BlurSamples; i++)
	{
		float3 p = float3(radius * VogelDiskSample(i, _BlurSamples, phi, 2.0), 0.0);
		float3 samplePosition = mul(p, frame) + positionWS;
		float2 pixel = floor(WorldToPixel(samplePosition, false)) + 0.5;
		
		if (any(pixel < 0.0 || pixel >= _ScreenSize.xy))
			continue;
		
		float sampleDepth = _Depth[pixel];
		float3 sampleWorldPos = PixelToWorld(pixel + 0.5, sampleDepth);
		float3 sampleNormal = GBufferNormal(pixel);
		float weight = saturate(1.0 - abs(dot(plane, float4(sampleWorldPos, 1.0))) * _TangentWeight * rcpEyeDepth);
		weight *= saturate(1.0 - Angle(normal, sampleNormal) * _NormalWeight * rcpEyeDepth);
		
		result += UnpackInput(_Input[pixel]) * weight;
		weightSum += weight;
	}
	
	result /= weightSum;
	
	_Result[dispatchThreadId] = PackOutput(result);
	//_Result[dispatchThreadId] = _Input[dispatchThreadId];
}

[numthreads(8, 8, 1)]
void Combine(uint2 dispatchThreadId : SV_DispatchThreadID)
{
	float2 uv = (dispatchThreadId + 0.5) * _ScreenSize.zw + _Jitter;
	uint4 inputs = _Input.Gather(_PointClampSampler, uv);
	float4 weights = BilinearWeights(uv, _ScreenSize.xy);
	
	float4 result = 0.0;
	
	[unroll]
	for (uint i = 0; i < 4; i++)
		result += UnpackInput(inputs[i]) * weights[i];
	
	// Remove weighting from final result
	result /= length(result.rgb);
	
	// Apply final modifier after temporal to reduce variance
	result.a = pow(result.a, _Strength);
	
	float4 visibilityCone = _VisibilityCone[dispatchThreadId];
	visibilityCone.xyz = GBufferNormal(visibilityCone);
	visibilityCone = BlendVisibiltyCones(visibilityCone, result);
	//visibilityCone = result;
	
	_VisibilityCone[dispatchThreadId] = PackGBufferNormal(visibilityCone.xyz, visibilityCone.w);
}